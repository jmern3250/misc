{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real2bits(value,bits=8,radius=1.5):\n",
    "    binary = np.zeros([bits,])\n",
    "    step = radius/(2**bits/2)\n",
    "    if value < 0:\n",
    "        binary[0] = 1\n",
    "    integer = int(np.floor(np.abs(value/step)))\n",
    "    done = False \n",
    "    i = bits-1\n",
    "    while not done: \n",
    "        binary[i] = integer % 2\n",
    "        integer = int(integer/2)\n",
    "#         pdb.set_trace()\n",
    "        if integer == 0:\n",
    "            done = True \n",
    "        else:\n",
    "            i -= 1 \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bits2real(bit_array,bits=8,radius=1.5):\n",
    "    step = radius/(2**(bits-1))\n",
    "    weights = np.zeros([bits,])\n",
    "#     weights[0] = -1.0\n",
    "    for i in range(bits-1):\n",
    "        weights[bits-i-1] = 2**i\n",
    "    value = weights.dot(bit_array)*step\n",
    "    if bool(bit_array[0]):\n",
    "        value *= -1.0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_bits2real(X, bits=8,radius=1.5): #FIXME \n",
    "    step = radius/(2**(bits-1))\n",
    "    weight_list = [0]\n",
    "    for i in range(bits-1):\n",
    "        power = bits - 2 - i \n",
    "        weight_list.append(2**power*step)\n",
    "    weight_list = np.array(weight_list)\n",
    "    weight_list = weight_list.reshape([-1,1])\n",
    "#     pdb.set_trace()\n",
    "    conversion_tensor = tf.constant(weight_list,\n",
    "                                   dtype=tf.float32)\n",
    "#     pdb.set_trace()\n",
    "    real_output = tf.matmul(X, conversion_tensor,\n",
    "                            transpose_a=False)\n",
    "    idx_array = np.zeros([bits,1])\n",
    "    idx_array[0] = 1\n",
    "    idx_tensor = tf.constant(idx_array,\n",
    "                            dtype=tf.float32)\n",
    "    neg = tf.matmul(X,idx_tensor)\n",
    "    neg_factor = tf.multiply(neg, tf.constant(-2, dtype=tf.float32))\n",
    "    scale = neg_factor + 1.0\n",
    "    real_output = tf.multiply(real_output, scale)\n",
    "#     tf.cond(tf.cast(neg,tf.bool), )\n",
    "    return real_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@function.Defun(tf.float32, tf.float32, tf.float32, tf.float32)\n",
    "def windowgrad(x,center,width,dy):\n",
    "    lo = center - width/2.0\n",
    "    hi = center + width/2.0\n",
    "    lo = 0.0\n",
    "    hi = 2.0\n",
    "    lo_mask = tf.greater_equal(x,lo)\n",
    "    lo_mask = tf.cast(lo_mask,dtype=tf.float32)\n",
    "    hi_mask = tf.less_equal(x,hi)\n",
    "    hi_mask = tf.cast(hi_mask,dtype=tf.float32)\n",
    "    out = tf.multiply(hi_mask, lo_mask)\n",
    "    out = tf.cast(out, dtype=tf.float32)\n",
    "    dx = tf.multiply(out,dy)\n",
    "    return dx, tf.constant(0,dtype=tf.float32), tf.constant(0,dtype=tf.float32) \n",
    "\n",
    "@function.Defun(tf.float32, tf.float32, tf.float32, grad_func=windowgrad)\n",
    "def window(x,center,width):\n",
    "    lo = center - width/2.0\n",
    "    hi = center + width/2.0\n",
    "    lo_mask = tf.greater_equal(x,lo)\n",
    "    lo_mask = tf.cast(lo_mask,dtype=tf.float32)\n",
    "    hi_mask = tf.less_equal(x,hi)\n",
    "    hi_mask = tf.cast(hi_mask,dtype=tf.float32)\n",
    "    out = tf.multiply(hi_mask, lo_mask)\n",
    "    out = tf.cast(out, dtype=tf.float32)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pseudo_huber(t, delta):\n",
    "    L = delta**2*(tf.sqrt(1 + (t/delta)**2)-1)\n",
    "    return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_MLP_wcustom(X,y,sizes,is_training,bits=8,dropout=False): \n",
    "    layers = {}\n",
    "    layers[0] = tf.layers.dense(X, sizes[0],\n",
    "                                activation = tf.nn.relu,\n",
    "                                use_bias=False,\n",
    "                                )\n",
    "    if dropout:\n",
    "        dropout_key = str(0)+'d' \n",
    "        layers[dropout_key] = tf.layers.dropout(layers[0],\n",
    "                                                rate=0.25,\n",
    "                                                training=is_training)\n",
    "    for j,  size in enumerate(sizes[1:]): \n",
    "        i = j+1\n",
    "        if dropout: \n",
    "            dropout_key_prior = str(i-1)+'d' \n",
    "            layers[i] = tf.layers.dense(layers[dropout_key_prior], size,\n",
    "                                    activation = tf.nn.relu,\n",
    "                                    use_bias=False,\n",
    "                                    )\n",
    "            dropout_key = str(i)+'d' \n",
    "            layers[dropout_key] = tf.layers.dropout(layers[dropout_key],\n",
    "                                                rate=0.25,\n",
    "                                                training=is_training)\n",
    "        else:\n",
    "            layers[i] = tf.layers.dense(layers[i-1], size,\n",
    "                                    activation = tf.nn.relu,\n",
    "                                    use_bias=False,\n",
    "                                    )\n",
    "\n",
    "    output_value = tf.layers.dense(layers[len(sizes)-1], bits,\n",
    "                                   activation = None,\n",
    "                                   use_bias=False,\n",
    "                                    ) #used relu to guarentee no negative values\n",
    "#     pdb.set_trace()\n",
    "#     center = tf.ones([1],dtype=tf.float32)\n",
    "#     width = tf.constant(1.0,dtype=tf.float32)\n",
    "#     output = window(output_value,center,width)\n",
    "    output = output_value\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bit_loss(X,y,bits=8,radius=1.5):\n",
    "    step = radius/(2**(bits-1))\n",
    "    weight_list = [radius]\n",
    "    for i in range(bits-1):\n",
    "        power = bits - 2 - i \n",
    "#         weight_list.append(2**power*step)\n",
    "        weight_list.append(power*step)\n",
    "    weight_list = np.array(weight_list)\n",
    "    weight_list = weight_list.reshape([1,-1])\n",
    "    conversion_tensor = tf.constant(weight_list,\n",
    "                                   dtype=tf.float32)\n",
    "#     pdb.set_trace()\n",
    "    diff = tf.subtract(X, y)\n",
    "    weighted_diff = tf.multiply(diff, conversion_tensor)\n",
    "#     loss = tf.nn.l2_loss(weighted_diff)\n",
    "    loss = pseudo_huber(weighted_diff, 0.1)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reg_loss(w_list):\n",
    "#     w_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    loss = 0.0\n",
    "    for w in w_list: \n",
    "        loss += tf.nn.l2_loss(w)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.variables.Variable"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_weights():\n",
    "#   return [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) if v.name.endswith('weights:0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SIZES = [128, 256, 512]\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None,1],name='Input')\n",
    "y = tf.placeholder(tf.float32, shape=[None,4],name='Correct_output')\n",
    "is_training = tf.placeholder(tf.bool,name='training')\n",
    "output = basic_MLP_wcustom(X,y,SIZES,is_training,bits=4,dropout=False)\n",
    "# real_output = tf_bits2real(output,bits=16)\n",
    "p_loss = bit_loss(output,y,bits=4,radius=1.5)\n",
    "w_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "# pdb.set_trace()\n",
    "r_loss = reg_loss(w_list)\n",
    "mean_loss = tf.reduce_mean(p_loss +  0.0001*r_loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-6) \n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "xd = np.arange(0, 1.49, 0.01)\n",
    "# xd = np.ones([1000,1])\n",
    "# np.random.shuffle(xd)\n",
    "yd = np.zeros([xd.shape[0],4])\n",
    "for i, x in enumerate(xd):\n",
    "    yd[i,:] = real2bits(x, bits=4, radius=1.5)\n",
    "#     yd[i] = bits2real(yd_, bits=16, radius=1.5)\n",
    "#     pdb.set_trace()\n",
    "xd = xd.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0462546\n",
      "0.0446514\n",
      "0.0430383\n",
      "0.0413877\n",
      "0.0396796\n",
      "0.0379438\n",
      "0.0362415\n",
      "0.0345823\n",
      "0.0329928\n",
      "0.0314923\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "#     idx = np.random.randint(0,xd.shape[0]-1,100)\n",
    "#     ml, _ = sess.run([mean_loss, train_step],feed_dict={X: xd[idx,:], y: yd[idx]})\n",
    "    ml, _ = sess.run([mean_loss, train_step],feed_dict={X: xd, y: yd})\n",
    "    if i % 1000 == 0:\n",
    "        print(ml)\n",
    "\n",
    "# total_loss, total_correct = run_model(sess, real_output, loss, xd, yd,\n",
    "#                                       epochs=1, batch_size=64, print_every=100,\n",
    "#                                       training=train_step, plot_losses=True)\n",
    "\n",
    "# iter_cnt,loss,np.sum(corr)/actual_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62751681]\n"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "print(sess.run([accuracy],feed_dict={X: xd, y: yd}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([tf.round(output)],feed_dict={X: xd, y: yd})[0][100:150,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(yd[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_35]",
   "language": "python",
   "name": "conda-env-ipykernel_35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
