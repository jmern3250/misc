{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real2bits(value,bits=8,radius=1.5):\n",
    "    binary = np.zeros([bits,])\n",
    "    step = radius/(2**bits/2)\n",
    "    if value < 0:\n",
    "        binary[0] = 1\n",
    "    integer = int(np.floor(np.abs(value/step)))\n",
    "    done = False \n",
    "    i = bits-1\n",
    "    while not done: \n",
    "        binary[i] = integer % 2\n",
    "        integer = int(integer/2)\n",
    "#         pdb.set_trace()\n",
    "        if integer == 0:\n",
    "            done = True \n",
    "        else:\n",
    "            i -= 1 \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bits2real(bit_array,bits=8,radius=1.5):\n",
    "    step = radius/(2**(bits-1))\n",
    "    weights = np.zeros([bits,])\n",
    "#     weights[0] = -1.0\n",
    "    for i in range(bits-1):\n",
    "        weights[bits-i-1] = 2**i\n",
    "    value = weights.dot(bit_array)*step\n",
    "    if bool(bit_array[0]):\n",
    "        value *= -1.0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_bits2real(X, bits=8,radius=1.5): #FIXME \n",
    "    step = radius/(2**(bits-1))\n",
    "    weight_list = [0]\n",
    "    for i in range(bits-1):\n",
    "        power = bits - 2 - i \n",
    "        weight_list.append(2**power*step)\n",
    "    weight_list = np.array(weight_list)\n",
    "    weight_list = weight_list.reshape([-1,1])\n",
    "#     pdb.set_trace()\n",
    "    conversion_tensor = tf.constant(weight_list,\n",
    "                                   dtype=tf.float32)\n",
    "#     pdb.set_trace()\n",
    "    real_output = tf.matmul(X, conversion_tensor,\n",
    "                            transpose_a=False)\n",
    "    idx_array = np.zeros([bits,1])\n",
    "    idx_array[0] = 1\n",
    "    idx_tensor = tf.constant(idx_array,\n",
    "                            dtype=tf.float32)\n",
    "    neg = tf.matmul(X,idx_tensor)\n",
    "    neg_factor = tf.multiply(neg, tf.constant(-2, dtype=tf.float32))\n",
    "    scale = neg_factor + 1.0\n",
    "    real_output = tf.multiply(real_output, scale)\n",
    "#     tf.cond(tf.cast(neg,tf.bool), )\n",
    "    return real_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@function.Defun(tf.float32, tf.float32, tf.float32, tf.float32)\n",
    "def windowgrad(x,center,width,dy):\n",
    "    lo = center - width/2.0\n",
    "    hi = center + width/2.0\n",
    "    lo = 0.0\n",
    "    hi = 2.0\n",
    "    lo_mask = tf.greater_equal(x,lo)\n",
    "    lo_mask = tf.cast(lo_mask,dtype=tf.float32)\n",
    "    hi_mask = tf.less_equal(x,hi)\n",
    "    hi_mask = tf.cast(hi_mask,dtype=tf.float32)\n",
    "    out = tf.multiply(hi_mask, lo_mask)\n",
    "    out = tf.cast(out, dtype=tf.float32)\n",
    "    dx = tf.multiply(out,dy)\n",
    "    return dx, tf.constant(0,dtype=tf.float32), tf.constant(0,dtype=tf.float32) \n",
    "\n",
    "@function.Defun(tf.float32, tf.float32, tf.float32, grad_func=windowgrad)\n",
    "def window(x,center,width):\n",
    "    lo = center - width/2.0\n",
    "    hi = center + width/2.0\n",
    "    lo_mask = tf.greater_equal(x,lo)\n",
    "    lo_mask = tf.cast(lo_mask,dtype=tf.float32)\n",
    "    hi_mask = tf.less_equal(x,hi)\n",
    "    hi_mask = tf.cast(hi_mask,dtype=tf.float32)\n",
    "    out = tf.multiply(hi_mask, lo_mask)\n",
    "    out = tf.cast(out, dtype=tf.float32)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_MLP_wcustom(X,y,sizes,is_training,bits=8,dropout=False): \n",
    "    layers = {}\n",
    "    layers[0] = tf.layers.dense(X, sizes[0],\n",
    "                                activation = tf.nn.relu,\n",
    "                                use_bias=False,\n",
    "                                )\n",
    "    if dropout:\n",
    "        dropout_key = str(0)+'d' \n",
    "        layers[dropout_key] = tf.layers.dropout(layers[0],\n",
    "                                                rate=0.25,\n",
    "                                                training=is_training)\n",
    "    for j,  size in enumerate(sizes[1:]): \n",
    "        i = j+1\n",
    "        if dropout: \n",
    "            dropout_key_prior = str(i-1)+'d' \n",
    "            layers[i] = tf.layers.dense(layers[dropout_key_prior], size,\n",
    "                                    activation = tf.nn.relu,\n",
    "                                    use_bias=False,\n",
    "                                    )\n",
    "            dropout_key = str(i)+'d' \n",
    "            layers[dropout_key] = tf.layers.dropout(layers[dropout_key],\n",
    "                                                rate=0.25,\n",
    "                                                training=is_training)\n",
    "        else:\n",
    "            layers[i] = tf.layers.dense(layers[i-1], size,\n",
    "                                    activation = tf.nn.relu,\n",
    "                                    use_bias=False,\n",
    "                                    )\n",
    "\n",
    "    output_value = tf.layers.dense(layers[len(sizes)-1], bits,\n",
    "                                   activation = None,\n",
    "                                   use_bias=False,\n",
    "                                    ) #used relu to guarentee no negative values\n",
    "#     pdb.set_trace()\n",
    "    center = tf.ones([1],dtype=tf.float32)\n",
    "    width = tf.constant(1.0,dtype=tf.float32)\n",
    "#     output = window(output_value,center,width)\n",
    "    output = output_value\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bit_loss(X,y,bits=8,radius=1.5):\n",
    "    step = radius/(2**(bits-1))\n",
    "    weight_list = [radius]\n",
    "    for i in range(bits-1):\n",
    "        power = bits - 2 - i \n",
    "#         weight_list.append(2**power*step)\n",
    "        weight_list.append(power*step)\n",
    "    weight_list = np.array(weight_list)\n",
    "    weight_list = weight_list.reshape([1,-1])\n",
    "    conversion_tensor = tf.constant(weight_list,\n",
    "                                   dtype=tf.float32)\n",
    "#     pdb.set_trace()\n",
    "    diff = tf.subtract(X, y)\n",
    "    weighted_diff = tf.multiply(diff, conversion_tensor)\n",
    "    loss = tf.nn.l2_loss(weighted_diff)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SIZES = [128, 256, 512]\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None,1],name='Input')\n",
    "y = tf.placeholder(tf.float32, shape=[None,4],name='Correct_output')\n",
    "is_training = tf.placeholder(tf.bool,name='training')\n",
    "output = basic_MLP_wcustom(X,y,SIZES,is_training,bits=4,dropout=False)\n",
    "# real_output = tf_bits2real(output,bits=16)\n",
    "loss = bit_loss(output,y,bits=4,radius=1.5)\n",
    "mean_loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-3) \n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "xd = np.arange(-1.49, 1.49, 0.01)\n",
    "# xd = np.ones([1000,1])\n",
    "# np.random.shuffle(xd)\n",
    "yd = np.zeros([xd.shape[0],4])\n",
    "for i, x in enumerate(xd):\n",
    "    yd[i,:] = real2bits(x, bits=4, radius=1.5)\n",
    "#     yd[i] = bits2real(yd_, bits=16, radius=1.5)\n",
    "#     pdb.set_trace()\n",
    "xd = xd.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18761\n",
      "0.00546597\n",
      "0.0260251\n",
      "0.600796\n",
      "0.0125024\n",
      "0.00127575\n",
      "0.00362035\n",
      "0.00348031\n",
      "0.0105769\n",
      "0.000734283\n",
      "0.412264\n",
      "0.017302\n",
      "0.0189731\n",
      "0.0183478\n",
      "0.0242712\n",
      "0.0689911\n",
      "0.0243588\n",
      "0.0915553\n",
      "0.000142189\n",
      "0.0650866\n",
      "0.0853367\n",
      "0.0151026\n",
      "0.125527\n",
      "0.0174418\n",
      "0.0162789\n",
      "0.00394045\n",
      "0.00194161\n",
      "0.740806\n",
      "0.0103936\n",
      "0.0119455\n",
      "0.170052\n",
      "0.350387\n",
      "0.0189355\n",
      "0.122888\n",
      "0.328072\n",
      "0.00365347\n",
      "0.0213579\n",
      "0.0019197\n",
      "0.0136743\n",
      "0.019757\n",
      "0.00314808\n",
      "0.27478\n",
      "0.000249423\n",
      "0.0103404\n",
      "0.920155\n",
      "0.000477844\n",
      "0.0152864\n",
      "0.0102045\n",
      "0.00264682\n",
      "0.0228537\n"
     ]
    }
   ],
   "source": [
    "for i in range(50000):\n",
    "    idx = np.random.randint(0,xd.shape[0]-1,1)\n",
    "    ml, _ = sess.run([mean_loss, train_step],feed_dict={X: xd[idx,:], y: yd[idx]})\n",
    "    if i % 1000 == 0:\n",
    "        print(ml)\n",
    "\n",
    "# total_loss, total_correct = run_model(sess, real_output, loss, xd, yd,\n",
    "#                                       epochs=1, batch_size=64, print_every=100,\n",
    "#                                       training=train_step, plot_losses=True)\n",
    "\n",
    "# iter_cnt,loss,np.sum(corr)/actual_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71476507]\n"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "print(sess.run([accuracy],feed_dict={X: xd, y: yd}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([tf.round(output)],feed_dict={X: xd, y: yd})[0][100:150,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(yd[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ipykernel_35]",
   "language": "python",
   "name": "conda-env-ipykernel_35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
