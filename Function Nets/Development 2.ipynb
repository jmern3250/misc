{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pdb\n",
    "import math \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real2bits(value,bits=8,radius=1.5):\n",
    "    binary = np.zeros([bits,])\n",
    "    step = radius/(2**bits/2)\n",
    "    if value < 0:\n",
    "        binary[0] = 1\n",
    "    integer = int(np.floor(np.abs(value/step)))\n",
    "    done = False \n",
    "    i = bits-1\n",
    "    while not done: \n",
    "        binary[i] = integer % 2\n",
    "        integer = int(integer/2)\n",
    "        if integer == 0:\n",
    "            done = True \n",
    "        else:\n",
    "            i -= 1 \n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bits2real(bit_array,bits=8,radius=1.5):\n",
    "    step = radius/(2**(bits-1))\n",
    "    weights = np.zeros([bits,])\n",
    "#     weights[0] = -1.0\n",
    "    for i in range(bits-1):\n",
    "        weights[bits-i-1] = 2**i\n",
    "    value = weights.dot(bit_array)*step\n",
    "    if bool(bit_array[0]):\n",
    "        value *= -1.0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_bits2real(X, bits=8,radius=1.5): #FIXME \n",
    "    step = radius/(2**(bits-1))\n",
    "    weight_list = [0]\n",
    "    for i in range(bits-1):\n",
    "        power = bits - 2 - i \n",
    "        weight_list.append(2**power*step)\n",
    "    weight_list = np.array(weight_list)\n",
    "    weight_list = weight_list.reshape([-1,1])\n",
    "#     pdb.set_trace()\n",
    "    conversion_tensor = tf.constant(weight_list,\n",
    "                                   dtype=tf.float32)\n",
    "#     pdb.set_trace()\n",
    "    real_output = tf.matmul(X, conversion_tensor,\n",
    "                            transpose_a=False)\n",
    "    idx_array = np.zeros([bits,1])\n",
    "    idx_array[0] = 1\n",
    "    idx_tensor = tf.constant(idx_array,\n",
    "                            dtype=tf.float32)\n",
    "    neg = tf.matmul(X,idx_tensor)\n",
    "    neg_factor = tf.multiply(neg, tf.constant(-2, dtype=tf.float32))\n",
    "    scale = neg_factor + 1.0\n",
    "    real_output = tf.multiply(real_output, scale)\n",
    "#     tf.cond(tf.cast(neg,tf.bool), )\n",
    "    return real_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pseudo_huber(t, delta):\n",
    "    L = delta**2*(tf.sqrt(1 + (t/delta)**2)-1)\n",
    "    return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_linear_loss(t, alpha, beta, gamma, zeta):\n",
    "    loss_pos = tf.nn.relu(alpha*t) - tf.nn.relu(alpha*(t-gamma)) + tf.nn.relu(beta*(t-gamma))\n",
    "    loss_neg = tf.nn.relu(-alpha*t) - tf.nn.relu(-alpha*(t+gamma)) +  tf.nn.relu(-beta*(t+gamma))\n",
    "#     loss_neg = 0\n",
    "    loss = loss_pos + loss_neg \n",
    "    loss = tf.reduce_sum(loss, axis=1)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_MLP(X,y,sizes,is_training,bits=8,dropout=False): \n",
    "    layers = {}\n",
    "    layers[0] = tf.layers.dense(X, sizes[0],\n",
    "                                activation = tf.nn.relu,\n",
    "                                use_bias=False,\n",
    "                                )\n",
    "    if dropout:\n",
    "        dropout_key = str(0)+'d' \n",
    "        layers[dropout_key] = tf.layers.dropout(layers[0],\n",
    "                                                rate=0.25,\n",
    "                                                training=is_training)\n",
    "    for j,  size in enumerate(sizes[1:]): \n",
    "        i = j+1\n",
    "        if dropout: \n",
    "            dropout_key_prior = str(i-1)+'d' \n",
    "            layers[i] = tf.layers.dense(layers[dropout_key_prior], size,\n",
    "                                    activation = tf.nn.relu,\n",
    "                                    use_bias=False,\n",
    "                                    )\n",
    "            dropout_key = str(i)+'d' \n",
    "            layers[dropout_key] = tf.layers.dropout(layers[dropout_key],\n",
    "                                                rate=0.25,\n",
    "                                                training=is_training)\n",
    "        else:\n",
    "            layers[i] = tf.layers.dense(layers[i-1], size,\n",
    "                                    activation = tf.nn.relu,\n",
    "                                    use_bias=False,\n",
    "                                    )\n",
    "\n",
    "    output = tf.layers.dense(layers[len(sizes)-1], bits,\n",
    "                                   activation = None,\n",
    "                                   use_bias=False,\n",
    "                                    ) #used relu to guarentee no negative values\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bit_loss(X,y,bits=8):\n",
    "    diff = tf.subtract(X, y)\n",
    "#     loss = tf.nn.l2_loss(diff)\n",
    "#     loss = pseudo_huber(diff, 0.1)\n",
    "    loss = multi_linear_loss(diff, alpha=0.1, beta=10, gamma=0.2, zeta=5)\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bit_loss(X,y,bits=8,radius=1.5):\n",
    "    step = radius/(2**(bits-1))\n",
    "    weight_list = [radius]\n",
    "    for i in range(bits-1):\n",
    "        power = bits - 2 - i \n",
    "#         weight_list.append(2**power*step)\n",
    "        weight_list.append(power*step)\n",
    "    weight_list = np.array(weight_list)\n",
    "    weight_list = weight_list.reshape([1,-1])\n",
    "    conversion_tensor = tf.constant(weight_list,\n",
    "                                   dtype=tf.float32)\n",
    "    diff = tf.subtract(X, y)\n",
    "    weighted_diff = tf.multiply(diff, conversion_tensor)\n",
    "    print(weighted_diff.shape)\n",
    "#     loss = tf.nn.l2_loss(weighted_diff)\n",
    "#     loss = pseudo_huber(weighted_diff, 0.1)\n",
    "    loss = multi_linear_loss(weighted_diff, alpha=0.1, beta=10, gamma=0.2, zeta=5)\n",
    "    print(loss.shape)    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_loss(w_list):\n",
    "#     w_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    loss = 0.0\n",
    "    for w in w_list: \n",
    "        loss += tf.nn.l2_loss(w)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_weights():\n",
    "#   return [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) if v.name.endswith('weights:0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZES = [128, 256, 512]\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None,1],name='Input')\n",
    "y = tf.placeholder(tf.float32, shape=[None,4],name='Correct_output')\n",
    "is_training = tf.placeholder(tf.bool,name='training')\n",
    "output = basic_MLP(X,y,SIZES,is_training,bits=4,dropout=False)\n",
    "# real_output = tf_bits2real(output,bits=16)\n",
    "# p_loss = weighted_bit_loss(output,y,bits=4,radius=1.5)\n",
    "p_loss = bit_loss(output,y)\n",
    "w_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "r_loss = reg_loss(w_list)\n",
    "mean_loss = tf.reduce_mean(p_loss +  0.00*r_loss)\n",
    "optimizer = tf.train.AdamOptimizer(1e-6) \n",
    "train_step = optimizer.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "xd = np.arange(0, 1.49, 0.01)\n",
    "# xd = np.ones([1000,1])\n",
    "# np.random.shuffle(xd)\n",
    "yd = np.zeros([xd.shape[0],4])\n",
    "for i, x in enumerate(xd):\n",
    "    yd[i,:] = real2bits(x, bits=4, radius=1.5)\n",
    "#     yd[i] = bits2real(yd_, bits=16, radius=1.5)\n",
    "xd = xd.reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4773\n",
      "10.1287\n",
      "8.7737\n",
      "7.6923\n",
      "6.81121\n",
      "6.2502\n",
      "5.81001\n",
      "5.72803\n",
      "5.72684\n",
      "5.72675\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "#     idx = np.random.randint(0,xd.shape[0]-1,100)\n",
    "#     ml, _ = sess.run([mean_loss, train_step],feed_dict={X: xd[idx,:], y: yd[idx]})\n",
    "    ml, _ = sess.run([mean_loss, train_step],feed_dict={X: xd, y: yd})\n",
    "    if i % 1000 == 0:\n",
    "        print(ml)\n",
    "\n",
    "# total_loss, total_correct = run_model(sess, real_output, loss, xd, yd,\n",
    "#                                       epochs=1, batch_size=64, print_every=100,\n",
    "#                                       training=train_step, plot_losses=True)\n",
    "\n",
    "# iter_cnt,loss,np.sum(corr)/actual_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75838923]\n"
     ]
    }
   ],
   "source": [
    "correct = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "print(sess.run([accuracy],feed_dict={X: xd, y: yd}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run([tf.round(output)],feed_dict={X: xd, y: yd})[0][100:150,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  0.  1.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]\n",
      " [ 0.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(yd[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "t = tf.placeholder(tf.float32, shape=[None,1])\n",
    "loss = multi_linear_loss(t, alpha=0.1, beta=1.0, gamma=0.4, zeta=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test = np.arange(-1,1,0.1).reshape([-1,1])\n",
    "loss_test = sess.run(loss, feed_dict={t:t_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd6WUCkJa7kopFYS03JVSKgj9f3LMBF3Ci2NrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2570a693f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(t_test, loss_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
