{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import PIL \n",
    "from PIL import Image\n",
    "import scipy.io as sio\n",
    "import glob \n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "import math\n",
    "import timeit\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 7, got 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-871ba3e587f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mWGAN_train\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_CIFAR10_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 7, got 6)"
     ]
    }
   ],
   "source": [
    "DATA = 1\n",
    "from WGAN_train import * \n",
    "X_train, _, _, _, _, _, mean_image = get_CIFAR10_data(num_training=20, num_validation=1, num_test=1)\n",
    "Y_train = np.mean(X_train, axis=3).reshape([-1,32,32,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "if DATA == 0:\n",
    "    X = tf.placeholder(tf.float32, [None, 480, 640, 3])\n",
    "    Y = tf.placeholder(tf.float32, [None, 480, 640, 1])\n",
    "elif DATA == 1:\n",
    "    X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "#     Y_ = tf.placeholder(tf.float32, [None, 245, 437, 3])\n",
    "    Y = tf.placeholder(tf.float32, [None, 32, 32, 1])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "with tf.variable_scope('Encoder') as enc: \n",
    "    latent_y = encoder(X, is_training, DATA)\n",
    "with tf.variable_scope('Decoder') as dec:\n",
    "    output = decoder(latent_y, is_training, DATA)\n",
    "# with tf.variable_scope(enc, reuse=True): \n",
    "#     latent_x = encoder(X, is_training, DATA)\n",
    "\n",
    "trans_loss = tf.nn.l2_loss(output-Y)\n",
    "# feat_loss = tf.nn.l2_loss(latent_x-latent_y)\n",
    "# total_loss = trans_loss + feat_loss*0.001    \n",
    "\n",
    "mean_loss = tf.reduce_mean(trans_loss)\n",
    "enc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='Encoder')\n",
    "dec_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope='Decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/final_model_enc\n",
      "INFO:tensorflow:Restoring parameters from ./models/final_model_dec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(device_count = {'GPU': 0}))\n",
    "enc_saver = tf.train.Saver(var_list=enc_vars)\n",
    "dec_saver = tf.train.Saver(var_list=dec_vars)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "if DATA == 1:\n",
    "    enc_saver.restore(sess, './models/final_model_enc')\n",
    "    dec_saver.restore(sess, './models/final_model_dec')\n",
    "# if DATA == 0:\n",
    "#     saver.restore(sess, './Models/PT_data_0_epochs_20_batchsize_5_rate_0.01_decay_1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87562e+06\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAAHUlEQVR4nGNkZMAPmAjIjyoYVTCq\nYKgqYEQisQIAjDkAQYk/XNsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x7F87734B2E10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "IMG , img_loss = sess.run([output, trans_loss], {X: X_train[i:i+1,...],\n",
    "                        Y: Y_train[i:i+1,...],\n",
    "                        is_training: False})\n",
    "\n",
    "print(img_loss)\n",
    "Image.fromarray(np.uint8(np.squeeze((IMG))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAADnklEQVR4nAXBXW/bVBgA4HN8Xn87\ntpO4SZq0zZKw0XRD7cYmFcYGYmg3XKABd7vmjj/DJZfAL0ATIAGCm0lMBQmhdrSwpR3pV9LEaWzH\nH8f28eF58PUXw7TZqpf3XubYJFtX/D3G/h1RMo+yhk3zFLxyDa0w5rlJvd1p3kX1Ls3bOwquaIGU\nY49DRqNOSpvi+qPGA6Rg6hV6ZQ2K2BL8gi0oQJYLbm2jrVB6fpzt3tjC7n+mVDlRQ49YVJJVSCVn\n+7VomM6nI509eXRH0kfhX75N5lINXEGxQQRjsTMZQx7MRW8n+rApr/He7sooZ1wUY6PAy+FFSugi\nu7yMG7ZRq7ZfN4Vnz+LJMKnLOE4RlGcj5M2LGRUtq1vaHzuzjW5r++A0pcIMTLSA4eDIN3t9z3Pq\n9iw/Gp095Kq633nr1yEq5iZO4A9tPet3O60LtSTEBXeHdl9kh713tp8e17CSAEzvlHBrfiqAiOOM\nOJ4pimplzcC3P/lxtoKcMZh8YqeRqYUiQohVsS1kJUmr8Fnt471Fki1Bnc5LSqEyQTcM8YJhjeQp\nyIWGFub93SzgEMzGvp0jMA3TkuX2eUGETHQyZmpxduv+9yOQ9dTq2RBmaqeFL2vvlfos5SIXMKsu\n4tWPvoV31w/fuNYlUURsm9Ow3w5zhhELdcxzSJa24cZWE0kcliiHQMqvKFEq64wkrilT93STSqBL\nVg4oBxYrTOA6FqHgoCCGeRr7k6YOOiFF5iUchSxMUdWxSVYUspAkUqHVI27Bd3ARQXZa1Muy/zLt\nErvV6mhqJUdQqpYFycbHy9GfbWOArlb9u8DI4JVb/fTmYR6riiRSNc3x25Xpl/30nN2rpI/lhKTJ\nZNoQfqeDex0kpArNgfwzLWgkc2CTp75bdmC4DD8dFEfXNkwdLAFw78k5EonIq3p/Mxi4cLx/8/Mv\nZjkFDQpi1R6C3Sw0TgyFL39gxAcDeqHu/90Y27IanJ2zyd5nuCNpNkhisYgwWvxweN1/FW32AMz4\nOV64Zf8WCOHuSh1FQdYqjzyxI3PnaDSXsIpUac4dA4D7v3xdYpy3HtdPTua1uNv/ClhU+EprHOcd\n2oYIvU8xwaK2tgjQ/uW65QnJQmeRv6Hlvx1nDmiok4EM6tVIb63+XJCzih0HXhJKwWw3fN6gMC3k\nyUAznCWi4dBpuQfjUegmNJNfxNZapa5gBan+NxPpzdtRlgxPKCrLk0BQrGZ1dVlDQPj/wd3ihGOt\nsw0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=32x32 at 0x7F8795A5F438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(np.squeeze((Y_train[i,:,:,:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAMK0lEQVR4nAEgDN/zAQUtCw1jsIui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\nGDWa3HnMDubj14cY1knBaBjkWPXBjIhAdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F87734B2860>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.fromarray(np.uint8(np.squeeze(X_train[i,:,:,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
